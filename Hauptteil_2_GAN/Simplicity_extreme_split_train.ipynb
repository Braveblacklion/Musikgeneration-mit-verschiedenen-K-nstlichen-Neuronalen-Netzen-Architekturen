{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense,Concatenate, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pypianoroll\n",
    "import numpy as np\n",
    "from pypianoroll import Multitrack, Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "run_id = '3001'\n",
    "music_name = 'gan/'\n",
    "\n",
    "RUN_FOLDER = 'run/'\n",
    "RUN_FOLDER += '_'.join([run_id, music_name])\n",
    "IMAGE_FOLDER = os.path.join(RUN_FOLDER, \"test_extreme/\")\n",
    "# Number of timestept the slices Pianorolls should have (Needs to be dividable by 16)\n",
    "pianrollLength = 128\n",
    "\n",
    "store_folder = os.path.join(RUN_FOLDER, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'store'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'output'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.mkdir(IMAGE_FOLDER)   \n",
    "\n",
    "#weight_init = RandomNormal(mean=0., stddev=0.02)\n",
    "weight_init = tf.keras.initializers.GlorotUniform(seed=None)\n",
    "#weight_init = tf.keras.initializers.he_uniform(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Note bounds for faster training\n",
    "lowestNotePossible = 20\n",
    "highestNotePossible = 108\n",
    "# possibleNotes mus be dividable by 4 else the Architekture needs to be changed\n",
    "possibleNotes = highestNotePossible - lowestNotePossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numpyArray for further us\n",
    "'''\n",
    "reshaped = np.load('data/preprocessed/midi_p128_dn88.npy')\n",
    "isNormalized = False\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_normalized_p128_dn88.npy')\n",
    "isNormalized = True\n",
    "'''\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_binarized_p128_dn88.npy')\n",
    "isNormalized = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE discriminator\n",
    "discriminator_input = Input(shape=(pianrollLength,possibleNotes,1), name='discriminator_input')\n",
    "\n",
    "x = discriminator_input\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (3,3), strides=2, kernel_initializer = weight_init)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (6,6), strides=2, kernel_initializer = weight_init)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = (6,6), strides=2, kernel_initializer = weight_init)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = (6,1), strides=2, kernel_initializer = weight_init)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = weight_init)(x)\n",
    "discriminator = Model(discriminator_input, discriminator_output, name= 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarydiscriminator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 50\n",
    "\n",
    "generator_input = Input(shape=(z_dim,), name='generator_input')\n",
    "generator_initial_dense_layer_size = (int(pianrollLength/4),int(possibleNotes/8),4)\n",
    "\n",
    "x = generator_input\n",
    "x = Dense(np.prod(generator_initial_dense_layer_size), kernel_initializer = weight_init)(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "\n",
    "#x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Reshape(generator_initial_dense_layer_size)(x)\n",
    "\n",
    "### Meldoy ###\n",
    "m = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "m = Conv2D(filters = 64, kernel_size = (6,6), padding='same', kernel_initializer = weight_init, name = 'generator_melody_conv_0')(m)\n",
    "#m = Activation('relu')(m)\n",
    "m = LeakyReLU()(m)\n",
    "m = Dropout(0.2)(m)\n",
    "\n",
    "m = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(m)\n",
    "m = Conv2D(filters = 64, kernel_size = (13,13), padding='same', kernel_initializer = weight_init, name = 'generator_melody_conv_1')(m)\n",
    "#m = Activation('relu')(m)\n",
    "m = LeakyReLU()(m)\n",
    "m = Dropout(0.2)(m)\n",
    "\n",
    "m = Conv2D(filters = 16, kernel_size = (1,13), padding='same', kernel_initializer = weight_init, name = 'generator_melody_conv_special')(m)\n",
    "#m = Activation('relu')(m)\n",
    "m = LeakyReLU()(m)\n",
    "m = Dropout(0.2)(m)\n",
    "\n",
    "m = Conv2D(filters = 1, kernel_size = (6,6), padding = 'same', kernel_initializer = weight_init)(m)        \n",
    "m = Activation('sigmoid')(m)\n",
    "##############\n",
    "\n",
    "### Bass Line ####\n",
    "b = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "b = Conv2D(filters = 64, kernel_size = (6,6), padding='same', kernel_initializer = weight_init, name = 'generator_bass_conv_0')(b)\n",
    "#b = Activation('relu')(b)\n",
    "b = LeakyReLU()(b)\n",
    "b = Dropout(0.2)(b)\n",
    "\n",
    "b = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(b)\n",
    "b = Conv2D(filters = 64, kernel_size = (13,13), padding='same', kernel_initializer = weight_init, name = 'generator_bass_conv_1')(b)\n",
    "b = LeakyReLU()(b)\n",
    "b = Dropout(0.2)(b)\n",
    "\n",
    "b = Conv2D(filters = 16, kernel_size = (1,13), padding='same', kernel_initializer = weight_init, name = 'generator_bass_conv_special')(b)\n",
    "#b = Activation('relu')(b)\n",
    "b = LeakyReLU()(b)\n",
    "b = Dropout(0.2)(b)\n",
    "\n",
    "b = Conv2D(filters = 1, kernel_size = (6,6), padding = 'same', kernel_initializer = weight_init)(b)        \n",
    "b = Activation('sigmoid')(b)\n",
    "##################\n",
    "\n",
    "x = Concatenate(axis=2)([m,b])\n",
    "\n",
    "#x = Conv2D(filters = 64, kernel_size = (5,5), padding='same', kernel_initializer = weight_init, name = 'generator_conv_1')(x)\n",
    "#x = Activation('relu')(x)\n",
    "\n",
    "#x = Conv2D(filters = 1, kernel_size = (6,6), padding = 'same', kernel_initializer = weight_init)(x)        \n",
    "#x = Activation('sigmoid')(x)\n",
    "\n",
    "\n",
    "generator_output = x\n",
    "generator = Model(generator_input, generator_output, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarygenerator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable(model, isTrainable):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = isTrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPILE DISCRIMINATOR\n",
    "discriminator.compile(\n",
    "optimizer=RMSprop(lr=0.0004)\n",
    ", loss = 'binary_crossentropy'\n",
    ",  metrics = ['accuracy']\n",
    ")\n",
    "        \n",
    "### COMPILE THE FULL GAN\n",
    "set_trainable(discriminator, False)\n",
    "\n",
    "model_input = Input(shape=(z_dim,), name='model_input')\n",
    "model_output = discriminator(generator(model_input))\n",
    "GANModel = Model(model_input, model_output)\n",
    "\n",
    "opti = RMSprop(learning_rate=0.0001)\n",
    "GANModel.compile(optimizer=opti , loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "set_trainable(discriminator, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file=os.path.join(RUN_FOLDER ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(discriminator, to_file=os.path.join(RUN_FOLDER ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(generator, to_file=os.path.join(RUN_FOLDER ,'viz/generator.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Midi_File(img, epoch, isNormalized):\n",
    "    gen_img = img.reshape(pianrollLength, 88)\n",
    "    result = np.zeros((pianrollLength, 128))\n",
    "    result[:,lowestNotePossible:highestNotePossible] = gen_img\n",
    "    #if isNormalized:\n",
    "    #result = (result > 0.1) * 255.\n",
    "    result = result * 255.\n",
    "    \n",
    "    track = Track(pianoroll=result, program=0, is_drum=False,name='my awesome piano')\n",
    "\n",
    "    multi = Multitrack()\n",
    "    multi.tracks[0] = track\n",
    "    pypianoroll.write(multi, os.path.join(IMAGE_FOLDER, str(epoch)+\".mid\"))\n",
    "    \n",
    "    multi.tracks[0].plot()\n",
    "    #fig.set_size_inches(100,100)\n",
    "    #plt.show()\n",
    "    plt.savefig(os.path.join(IMAGE_FOLDER, str(epoch)+\"_pianoroll.png\"), format='png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, z_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        #Rescale images 0 - 1\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(5,15))\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(np.squeeze(gen_imgs[cnt, :,:,:]), cmap = 'gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(os.path.join(IMAGE_FOLDER, \"%d_multi.png\" % epoch))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_normal(epochs, batch_size=32):\n",
    "    # Save the Generator and discriminator models\n",
    "    #save_model(generator, os.path.join(RUN_FOLDER, 'images/generator'))\n",
    "    #save_model(discriminator, os.path.join(RUN_FOLDER, 'images/discriminator'))\n",
    "    #save_model(GANModel, os.path.join(RUN_FOLDER, r\"images/GANModel\"))\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    # Label Smoothening\n",
    "    valid_smoothened = np.random.uniform(low=0.8, high=1.0, size=(batch_size,1))\n",
    "    fake_smoothened = np.random.uniform(low=0.0, high=0.05, size=(batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------      \n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        # Select a random half of images\n",
    "        idx = np.random.randint(0, reshaped.shape[0], batch_size)\n",
    "        imgs = reshaped[idx]\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Train the discriminator (real classified as ones and generated as zeros)\n",
    "        # ---------------------\n",
    "        d_loss_real, d_acc_real =  discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake, d_acc_fake =  discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        g_loss = GANModel.train_on_batch(noise, valid)\n",
    "        #print (\"%d [G loss: %.3f] [G acc: %.3f]\" % (epoch, g_loss[0], g_loss[1]))\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Save Losses for evaluation\n",
    "        # ---------------------\n",
    "        d = [d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake]\n",
    "        d_losses.append(d)\n",
    "        g = [g_loss[0], g_loss[1]]\n",
    "        g_losses.append(g)\n",
    "        \n",
    "        \n",
    "        if (epoch % 100 == 0): \n",
    "            # Save an example\n",
    "            fig=plt.figure(figsize=(16, 64))\n",
    "            plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(IMAGE_FOLDER, str(epoch)+\".png\"), format='png')\n",
    "            generate_Midi_File(gen_imgs[0, :, :, 0], epoch, isNormalized)\n",
    "            plt.close()\n",
    "            \n",
    "            # Save some examples\n",
    "            sample_images(epoch)\n",
    "            \n",
    "            # Continuiously save a plot with the new values to see the development of the loss\n",
    "            fig = plt.figure()\n",
    "            plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "            plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "            plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "            plt.plot([x[0] for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "            plt.xlabel('batch', fontsize=18)\n",
    "            plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "            # plt.xlim(0, 2000)\n",
    "            #plt.ylim(0, 50)\n",
    "\n",
    "            plt.savefig(os.path.join(IMAGE_FOLDER, \"loss_chart.png\"), format='png')\n",
    "            plt.show()\n",
    "            plt.close\n",
    "            # Save the loss arrays\n",
    "            np.save(os.path.join(IMAGE_FOLDER, \"D_loss.npy\"), d_losses)\n",
    "            np.save(os.path.join(IMAGE_FOLDER, \"G_loss.npy\"), g_losses)\n",
    "            \n",
    "            if (epoch % 1000 == 0):\n",
    "                GANModel.save(os.path.join(IMAGE_FOLDER, 'GANModel_'+str(epoch)+'_loss_'+str(g_loss[0])+'.h5'))\n",
    "                discriminator.save(os.path.join(IMAGE_FOLDER, 'discriminator_'+str(epoch)+'_loss_'+str(d_loss)+'.h5'))\n",
    "                generator.save(os.path.join(IMAGE_FOLDER, 'generator_'+str(epoch)+'_loss_'+str(g_loss[0])+'.h5'))\n",
    "                \n",
    "                \n",
    "        # Plot the progress\n",
    "        if (epoch % 10 == 0):\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake, g_loss[0], g_loss[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "train_normal(100001, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "#plt.xlim(0, 20000)\n",
    "plt.ylim(0, 30)\n",
    "\n",
    "plt.savefig(os.path.join(IMAGE_FOLDER, \"loss_chart2.png\"), format='png')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/6537563\n",
    "# Beep to tell training finished\n",
    "import winsound\n",
    "frequency = 300  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_losses = np.load(os.path.join(IMAGE_FOLDER, \"D_loss.npy\"))\n",
    "#g_losses = np.load(os.path.join(IMAGE_FOLDER, \"G_loss.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator = load_model(os.path.join(IMAGE_FOLDER, \"First_run/generator_10000_loss_30.628813.h5\"))\n",
    "#discriminator = load_model(os.path.join(IMAGE_FOLDER, \"First_run/discriminator_10000_loss_5.734544512425027e-14.h5\"))\n",
    "#GANModel = load_model(os.path.join(IMAGE_FOLDER, \"First_run/GANModel_10000_loss_30.628813.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

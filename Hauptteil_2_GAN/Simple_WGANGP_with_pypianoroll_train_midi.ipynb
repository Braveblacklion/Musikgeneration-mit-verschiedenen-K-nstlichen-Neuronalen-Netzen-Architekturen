{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers.merge import _Merge\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pypianoroll\n",
    "import numpy as np\n",
    "from pypianoroll import Multitrack, Track\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "run_id = '4001'\n",
    "music_name = 'wgan-gp/'\n",
    "\n",
    "RUN_FOLDER = 'run/'\n",
    "RUN_FOLDER += '_'.join([run_id, music_name])\n",
    "\n",
    "# Number of timestept the slices Pianorolls should have (Needs to be dividable by 16)\n",
    "pianrollLength = 128\n",
    "\n",
    "store_folder = os.path.join(RUN_FOLDER, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'store'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'output'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "\n",
    "mode = 'build' # 'load' # \n",
    "\n",
    "#weight_init = RandomNormal(mean=0.05, stddev=0.05)\n",
    "weight_init = tf.keras.initializers.he_uniform(seed=16)\n",
    "# Clip Threshold for weight clipping should be in range [-0.01, 0.01]\n",
    "clip_threshold = 0.01\n",
    "# Set Note bounds for faster training\n",
    "lowestNotePossible = 20\n",
    "highestNotePossible = 108\n",
    "# possibleNotes mus be dividable by 4 else the Architekture needs to be changed\n",
    "possibleNotes = highestNotePossible - lowestNotePossible\n",
    "\n",
    "input_dim = (pianrollLength,possibleNotes,1)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "grad_weight = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numpyArray for further us\n",
    "'''\n",
    "reshaped = np.load('data/preprocessed/midi_p128_dn88.npy')\n",
    "isNormalized = False\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_normalized_p128_dn88.npy')\n",
    "isNormalized = True\n",
    "'''\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_binarized_p128_dn88.npy')\n",
    "isNormalized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    # Provides a (random) weighted average between real and generated image samples\n",
    "    def call(self, inputs, **kwargs):\n",
    "        #https://stackoverflow.com/a/58136256\n",
    "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jacobgil/keras-grad-cam/issues/17#issuecomment-398053700\n",
    "def _compute_gradients(tensor, var_list):\n",
    "    grads = tf.gradients(tensor, var_list)\n",
    "    return [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(var_list, grads)]\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, interpolated_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = _compute_gradients(y_pred, [interpolated_samples])[0]\n",
    "    #gradients = K.gradients(y_pred, interpolated_samples)[0]\n",
    "\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://github.com/ChengBinJin/WGAN-GP-tensorflow/blob/master/src/wgan_gp.py 90-98\n",
    "def gradient_penalty():\n",
    "    alpha = tf.random_uniform(shape=[batch_size, 1, 1, 1], minval=0., maxval=1.)\n",
    "    differences = g_samples - Y\n",
    "    interpolates = Y + (alpha * differences)\n",
    "    gradients = tf.gradients(discriminator(interpolates, is_reuse=True), [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2, 3]))\n",
    "    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE discriminator\n",
    "discriminator_input = Input(shape=(pianrollLength,possibleNotes,1), name='discriminator_input')\n",
    "\n",
    "x = discriminator_input\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), strides=2, padding = 'same', kernel_initializer = weight_init, name = 'discriminator_conv_0')(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), strides=2, padding = 'same', kernel_initializer = weight_init, name = 'discriminator_conv_1')(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), strides=2, padding = 'same', kernel_initializer = weight_init, name = 'discriminator_conv_2')(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), strides=1, padding = 'same', kernel_initializer = weight_init, name = 'discriminator_conv_3')(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "discriminator_output = Dense(1, activation='sigmoid', kernel_initializer = weight_init)(x)\n",
    "discriminator = Model(discriminator_input, discriminator_output, name= 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarydiscriminator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "generator_input = Input(shape=(z_dim,), name='generator_input')\n",
    "generator_initial_dense_layer_size = (int(pianrollLength/4),int(possibleNotes/4),8)\n",
    "\n",
    "x = generator_input\n",
    "x = Dense(np.prod(generator_initial_dense_layer_size), kernel_initializer = weight_init)(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Reshape(generator_initial_dense_layer_size)(x)\n",
    "\n",
    "x = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), padding='same', kernel_initializer = weight_init, name = 'generator_conv_0')(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)  \n",
    "\n",
    "x = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), padding='same', kernel_initializer = weight_init, name = 'generator_conv_1')(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x) \n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), padding = 'same', kernel_initializer = weight_init, name = 'generator_conv_2')(x)\n",
    "x = BatchNormalization(momentum=0.9)(x)\n",
    "# x = LeakyReLU()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters = 1, kernel_size = (5,5), padding = 'same', kernel_initializer = weight_init)(x)        \n",
    "x = Activation('sigmoid')(x)\n",
    "\n",
    "\n",
    "generator_output = x\n",
    "generator = Model(generator_input, generator_output, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarygenerator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable(model, isTrainable):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = isTrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein loss function (Forster S. 117)\n",
    "def wasserstein(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### COMPILE DISCRIMINATOR ###\n",
    "#############################\n",
    "\n",
    "# Freeze generator's layers while training critic\n",
    "set_trainable(generator, False)\n",
    "\n",
    "# Image input (real sample)\n",
    "real_img = Input(shape=input_dim)\n",
    "\n",
    "# Fake image\n",
    "z_disc = Input(shape=(z_dim,))\n",
    "fake_img = generator(z_disc)\n",
    "\n",
    "# critic determines validity of the real and fake images\n",
    "fake = discriminator(fake_img)\n",
    "valid = discriminator(real_img)\n",
    "\n",
    "# Construct weighted average between real and fake images\n",
    "interpolated_img = RandomWeightedAverage(batch_size)([real_img, fake_img])\n",
    "# Determine validity of weighted sample\n",
    "validity_interpolated = discriminator(interpolated_img)\n",
    "\n",
    "# Use Python partial to provide loss function with additional\n",
    "# 'interpolated_samples' argument\n",
    "partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                          interpolated_samples=interpolated_img)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "discriminator_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "\n",
    "discriminator_model.compile(\n",
    "            loss=[wasserstein,wasserstein, partial_gp_loss]\n",
    "            ,optimizer=Adam(lr=0.0002, beta_1=0.5)\n",
    "            ,loss_weights=[1, 1, grad_weight]\n",
    "            )\n",
    "\n",
    "############################\n",
    "### COMPILE THE FULL GAN ###\n",
    "############################\n",
    "set_trainable(discriminator, False)\n",
    "set_trainable(generator, True)\n",
    "\n",
    "model_input = Input(shape=(z_dim,), name='model_input')\n",
    "model_output = discriminator(generator(model_input))\n",
    "GANModel = Model(model_input, model_output)\n",
    "\n",
    "GANModel.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5) , loss=wasserstein) #, metrics=['accuracy'])\n",
    "\n",
    "set_trainable(discriminator, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file=os.path.join(RUN_FOLDER ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(discriminator, to_file=os.path.join(RUN_FOLDER ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(generator, to_file=os.path.join(RUN_FOLDER ,'viz/generator.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Midi_File(img, epoch, isNormalized):\n",
    "    gen_img = img.reshape(128, 88)\n",
    "    result = np.zeros((pianrollLength, 128))\n",
    "    result[:,lowestNotePossible:highestNotePossible] = gen_img\n",
    "    #if isNormalized:\n",
    "    #result = (result > 0.1) * 255.\n",
    "    result = result * 255.\n",
    "    \n",
    "    track = Track(pianoroll=result, program=0, is_drum=False,name='my awesome piano')\n",
    "\n",
    "    multi = Multitrack()\n",
    "    multi.tracks[0] = track\n",
    "    pypianoroll.write(multi, os.path.join(RUN_FOLDER, \"images/\"+str(epoch)+\".mid\"))\n",
    "    \n",
    "    multi.tracks[0].plot()\n",
    "    #fig.set_size_inches(100,100)\n",
    "    #plt.show()\n",
    "    plt.savefig(os.path.join(RUN_FOLDER, \"images/\"+str(epoch)+\"_pianoroll.png\"), format='png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_normal(epochs, batch_size=128):\n",
    "    # Save the Generator and discriminator models\n",
    "    #save_model(generator, os.path.join(RUN_FOLDER, 'images/generator'))\n",
    "    #save_model(discriminator, os.path.join(RUN_FOLDER, 'images/discriminator'))\n",
    "    #save_model(GANModel, os.path.join(RUN_FOLDER, r\"images/GANModel\"))\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1), dtype=np.float32)\n",
    "    fake = -np.ones((batch_size, 1), dtype=np.float32)\n",
    "    dummy = np.zeros((batch_size, 1), dtype=np.float32) # Dummy gt for gradient penalty\n",
    "    # Label Smoothening\n",
    "    #valid_smoothened = np.random.uniform(low=0.995, high=1.0, size=(batch_size,1))\n",
    "    #fake_smoothened = np.random.uniform(low=0.0, high=0.005, size=(batch_size,1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for x in range(5):\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------  \n",
    "            valid = np.ones((batch_size, 1), dtype=np.float32)\n",
    "            fake = -np.ones((batch_size, 1), dtype=np.float32)\n",
    "            dummy = np.zeros((batch_size, 1), dtype=np.float32) # Dummy gt for gradient penalty\n",
    "            \n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, reshaped.shape[0], batch_size)\n",
    "            true_imgs = reshaped[idx]\n",
    "            \n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        \n",
    "            # ---------------------\n",
    "            #  Train the discriminator (real classified as ones and generated as zeros)\n",
    "            # ---------------------\n",
    "            d_loss = discriminator_model.train_on_batch([true_imgs, noise], [valid, fake, dummy])\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        for x in range(1):\n",
    "            valid = np.ones((batch_size,1), dtype=np.float32)\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            g_loss = GANModel.train_on_batch(noise, valid)\n",
    "        #print (\"%d [G loss: %.3f] [G acc: %.3f]\" % (epoch, g_loss[0], g_loss[1]))\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Save Losses for evaluation\n",
    "        # ---------------------\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        \n",
    "        if (epoch % 100 == 0): \n",
    "            # Save an example\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            fig=plt.figure(figsize=(64, 64))\n",
    "            plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(RUN_FOLDER, \"images/\"+str(epoch)+\".png\"), format='png')\n",
    "            generate_Midi_File(gen_imgs[0, :, :, 0], epoch, isNormalized)\n",
    "            plt.close()\n",
    "            \n",
    "            # Continuiously save a plot with the new values to see the development of the loss\n",
    "            fig = plt.figure()\n",
    "            plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "            plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "            plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "            plt.plot([x for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "            plt.xlabel('batch', fontsize=18)\n",
    "            plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "            # plt.xlim(0, 2000)\n",
    "            #plt.ylim(0, 50)\n",
    "\n",
    "            plt.savefig(os.path.join(RUN_FOLDER, \"images/loss_chart.png\"), format='png')\n",
    "            plt.show()\n",
    "            plt.close\n",
    "            # Save the loss arrays\n",
    "            np.save(os.path.join(RUN_FOLDER, \"images/D_loss.npy\"), d_losses)\n",
    "            np.save(os.path.join(RUN_FOLDER, \"images/G_loss.npy\"), g_losses)\n",
    "            \n",
    "            if (epoch % 1000 == 0):\n",
    "                GANModel.save(os.path.join(RUN_FOLDER, 'images/GANModel_'+str(epoch)+'_loss_'+str(g_loss)+'.h5'))\n",
    "                discriminator.save(os.path.join(RUN_FOLDER, 'images/discriminator_'+str(epoch)+'_loss_'+str(d_loss)+'.h5'))\n",
    "                generator.save(os.path.join(RUN_FOLDER, 'images/generator_'+str(epoch)+'_loss_'+str(g_loss)+'.h5'))\n",
    "                \n",
    "                \n",
    "        # Plot the progress\n",
    "        if (epoch % 10 == 0):\n",
    "            print (\"%d [D loss: (%.1f)(R %.1f, F %.1f, G %.1f)] [G loss: %.1f]\" % (epoch, d_loss[0], d_loss[1],d_loss[2],d_loss[3],g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "train_normal(10001, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 10000)\n",
    "plt.ylim(0, 50)\n",
    "\n",
    "plt.savefig(os.path.join(RUN_FOLDER, \"images/loss_chart4.png\"), format='png')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/6537563\n",
    "# Beep to tell training finished\n",
    "import winsound\n",
    "frequency = 300  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_losses = np.load(os.path.join(RUN_FOLDER, \"images/D_loss.npy\"))\n",
    "#g_losses = np.load(os.path.join(RUN_FOLDER, \"images/G_loss.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

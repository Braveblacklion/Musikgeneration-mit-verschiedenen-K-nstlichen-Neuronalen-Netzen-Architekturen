{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pypianoroll\n",
    "import numpy as np\n",
    "from pypianoroll import Multitrack, Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "run_id = '3000'\n",
    "music_name = 'wgan/'\n",
    "\n",
    "RUN_FOLDER = 'run/'\n",
    "RUN_FOLDER += '_'.join([run_id, music_name])\n",
    "\n",
    "# Number of timestept the slices Pianorolls should have (Needs to be dividable by 16)\n",
    "pianrollLength = 128\n",
    "\n",
    "store_folder = os.path.join(RUN_FOLDER, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'store'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'output'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    \n",
    "\n",
    "\n",
    "mode = 'build' # 'load' # \n",
    "# Clip Threshold for weight clipping should be in range [-0.01, 0.01]\n",
    "clip_threshold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Note bounds for faster training\n",
    "lowestNotePossible = 20\n",
    "highestNotePossible = 108\n",
    "# possibleNotes mus be dividable by 4 else the Architekture needs to be changed\n",
    "possibleNotes = highestNotePossible - lowestNotePossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numpyArray for further us\n",
    "'''\n",
    "reshaped = np.load('data/preprocessed/midi_p128_dn88.npy')\n",
    "isNormalized = False\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_normalized_p128_dn88.npy')\n",
    "isNormalized = True\n",
    "'''\n",
    "\n",
    "reshaped = np.load('data/preprocessed/midi_binarized_p128_dn88.npy')\n",
    "isNormalized = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE discriminator\n",
    "discriminator_input = Input(shape=(pianrollLength,possibleNotes,1), name='discriminator_input')\n",
    "\n",
    "x = discriminator_input\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), strides=2, padding = 'same', name = 'discriminator_conv_0')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), strides=2, padding = 'same', name = 'discriminator_conv_1')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), strides=2, padding = 'same', name = 'discriminator_conv_2')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), strides=1, padding = 'same', name = 'discriminator_conv_3')(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "discriminator_output = Dense(1)(x)\n",
    "discriminator = Model(discriminator_input, discriminator_output, name= 'discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarydiscriminator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "generator_input = Input(shape=(z_dim,), name='generator_input')\n",
    "generator_initial_dense_layer_size = (int(pianrollLength/4),int(possibleNotes/4),8)\n",
    "\n",
    "x = generator_input\n",
    "x = Dense(np.prod(generator_initial_dense_layer_size))(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "\n",
    "x = LeakyReLU()(x)\n",
    "x = Reshape(generator_initial_dense_layer_size)(x)\n",
    "\n",
    "x = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "x = Conv2D(filters = 128, kernel_size = (5,5), padding='same', name = 'generator_conv_0')(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "x = LeakyReLU()(x)   \n",
    "\n",
    "x = UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest')(x)\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), padding='same', name = 'generator_conv_1')(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "x = LeakyReLU()(x)  \n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (5,5), padding = 'same', name = 'generator_conv_2')(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "x = LeakyReLU()(x)  \n",
    "\n",
    "x = Conv2D(filters = 1, kernel_size = (5,5), padding = 'same')(x)        \n",
    "x = Activation('sigmoid')(x)\n",
    "\n",
    "\n",
    "generator_output = x\n",
    "generator = Model(generator_input, generator_output, name='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/45199301\n",
    "# Save the summary to a file \n",
    "#from contextlib import redirect_stdout\n",
    "\n",
    "#with open(os.path.join(store_folder, 'modelsummarygenerator.txt'), 'w') as f:\n",
    "#    with redirect_stdout(f):\n",
    "#        generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable(model, isTrainable):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = isTrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein loss function (Forster S. 117)\n",
    "def wasserstein(y_true, y_pred):\n",
    "    return -K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPILE DISCRIMINATOR\n",
    "discriminator.compile(\n",
    "optimizer=RMSprop(lr=0.00005)\n",
    ", loss = wasserstein #,  metrics = ['accuracy']\n",
    ")\n",
    "        \n",
    "### COMPILE THE FULL GAN\n",
    "set_trainable(discriminator, False)\n",
    "\n",
    "model_input = Input(shape=(z_dim,), name='model_input')\n",
    "model_output = discriminator(generator(model_input))\n",
    "GANModel = Model(model_input, model_output)\n",
    "\n",
    "opti = RMSprop(learning_rate=0.00005)\n",
    "GANModel.compile(optimizer=opti , loss=wasserstein)#, metrics=['accuracy'])\n",
    "\n",
    "set_trainable(discriminator, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file=os.path.join(RUN_FOLDER ,'viz/model.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(discriminator, to_file=os.path.join(RUN_FOLDER ,'viz/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "#plot_model(generator, to_file=os.path.join(RUN_FOLDER ,'viz/generator.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_normal(epochs, batch_size=128):\n",
    "    # Save the Generator and discriminator models\n",
    "    #save_model(generator, os.path.join(RUN_FOLDER, 'images/generator'))\n",
    "    #save_model(discriminator, os.path.join(RUN_FOLDER, 'images/discriminator'))\n",
    "    #save_model(GANModel, os.path.join(RUN_FOLDER, r\"images/GANModel\"))\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = -np.ones((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------    \n",
    "        # In a WGAN the Discriminator is trained multiple time\n",
    "        for x in range(5):\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, reshaped.shape[0], batch_size)\n",
    "            imgs = reshaped[idx]\n",
    "        \n",
    "            # ---------------------\n",
    "            #  Train the discriminator (real classified as ones and generated as zeros)\n",
    "            # ---------------------\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake =  discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "            \n",
    "            # Weight clipping (Forster S.119)\n",
    "            for l in discriminator.layers:\n",
    "                weights = l.get_weights()\n",
    "                weights = [np.clip(w, -clip_threshold, clip_threshold) for w in weights]\n",
    "                l.set_weights(weights)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        for x in range(1):\n",
    "            g_loss = GANModel.train_on_batch(noise, valid)\n",
    "        \n",
    "        # ---------------------\n",
    "        #  Save Losses for evaluation\n",
    "        # ---------------------\n",
    "        d = [d_loss, d_loss_real, d_loss_fake]\n",
    "        d_losses.append(d)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "        \n",
    "        if (epoch % 100 == 0): \n",
    "            # Save an example\n",
    "            fig=plt.figure(figsize=(64, 64))\n",
    "            plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.savefig(os.path.join(RUN_FOLDER, \"output/\"+str(epoch)+\".png\"), format='png')\n",
    "            plt.close()\n",
    "            \n",
    "            if (epoch % 1000 == 0):\n",
    "                GANModel.save(os.path.join(RUN_FOLDER, 'weights/GANModel_'+str(epoch)+'_loss_'+str(g_loss)+'.h5'))\n",
    "                discriminator.save(os.path.join(RUN_FOLDER, 'weights/discriminator_'+str(epoch)+'_loss_'+str(d_loss)+'.h5'))\n",
    "                generator.save(os.path.join(RUN_FOLDER, 'weights/generator_'+str(epoch)+'_loss_'+str(g_loss)+'.h5'))\n",
    "                \n",
    "                # Continuiously save a plot with the new values to see the development of the loss\n",
    "                fig = plt.figure()\n",
    "                plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "                plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "                plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "                plt.plot([g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "                plt.xlabel('batch', fontsize=18)\n",
    "                plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "                # plt.xlim(0, 2000)\n",
    "                #plt.ylim(-50, 50)\n",
    "\n",
    "                plt.savefig(os.path.join(RUN_FOLDER, \"output/loss_chart.png\"), format='png')\n",
    "                plt.show()\n",
    "                plt.close\n",
    "                # Save the loss arrays\n",
    "                np.save(os.path.join(RUN_FOLDER, \"output/D_loss.npy\"), d_losses)\n",
    "                np.save(os.path.join(RUN_FOLDER, \"output/G_loss.npy\"), g_losses)\n",
    "        # Plot the progress\n",
    "        if (epoch % 10 == 0):\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)]  [G loss: %.3f] \" % (epoch, d_loss, d_loss_real, d_loss_fake, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "train_normal(10001, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 10000)\n",
    "plt.ylim(-300000, 300000)\n",
    "\n",
    "plt.savefig(os.path.join(RUN_FOLDER, \"output/loss_chart3.png\"), format='png')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelle: https://stackoverflow.com/a/6537563\n",
    "# Beep to tell training finished\n",
    "import winsound\n",
    "frequency = 300  # Set Frequency To 2500 Hertz\n",
    "duration = 1000  # Set Duration To 1000 ms == 1 second\n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_losses = np.load(os.path.join(RUN_FOLDER, \"images/D_loss.npy\"))\n",
    "#g_losses = np.load(os.path.join(RUN_FOLDER, \"images/G_loss.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

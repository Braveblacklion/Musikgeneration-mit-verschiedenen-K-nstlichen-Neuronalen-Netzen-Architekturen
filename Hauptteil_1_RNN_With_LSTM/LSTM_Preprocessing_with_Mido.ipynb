{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose: Training a model to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras\n",
    "\n",
    "from mido import MidiFile ,MetaMessage, Message, MidiTrack\n",
    "\n",
    "from models.LSTM_SELFTRY import get_distinct, create_lookups, prepare_sequences, create_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'compose'\n",
    "run_id = '1117'\n",
    "music_name = 'midis'\n",
    "\n",
    "run_folder = 'run/{}/'.format(section)\n",
    "run_folder += '_'.join([run_id, music_name])\n",
    "\n",
    "\n",
    "store_folder = os.path.join(run_folder, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(run_folder):\n",
    "    ### EDITED #################\n",
    "    # Failes if subdirectorys (1117/midis) missing \n",
    "    # os.mkdir(run_folder)\n",
    "    # Creates all needed subdirectorys (1117/midis) \n",
    "    os.makedirs(run_folder)\n",
    "    ############################\n",
    "    os.mkdir(os.path.join(run_folder, 'store'))\n",
    "    os.mkdir(os.path.join(run_folder, 'output'))\n",
    "    os.mkdir(os.path.join(run_folder, 'weights'))\n",
    "    os.mkdir(os.path.join(run_folder, 'viz'))\n",
    "    \n",
    "\n",
    "\n",
    "mode = 'build' # 'load' # \n",
    "\n",
    "# data params\n",
    "#intervals = range(1)\n",
    "seq_len = 64\n",
    "\n",
    "# model params\n",
    "embed_size = 200\n",
    "rnn_units = 256\n",
    "use_attention = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searches all .mid Files in the given directory and its subdirectorys\n",
    "def readFiles(directory):\n",
    "    global music_list\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mid\"):\n",
    "                music_list.append(os.path.join(root, file))\n",
    "                #print(os.path.join(root, file))\n",
    "                    \n",
    "#(Quelle: https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Returns a list of all the midi Files in the given data_folder and its subfolders\n",
    "def get_Music_List(directory):\n",
    "    global music_list\n",
    "    music_list = []\n",
    "    readFiles(directory)\n",
    "    return music_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_list = get_Music_List(data_folder)\n",
    "len(music_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isOnlyMonoTrackMode = True\n",
    "monoTrackMidis = []\n",
    "\n",
    "if mode == 'build':\n",
    "    \n",
    "    music_list = get_Music_List(data_folder)\n",
    "    print(len(music_list), 'files in total')\n",
    "\n",
    "    for i, file in enumerate(music_list):\n",
    "        print(i+1, \"Parsing %s\" % file)\n",
    "        midi_score = MidiFile(os.path.join(file))\n",
    "        #print('Ticks per beat: ' + str(midi_score.ticks_per_beat))\n",
    "        if (midi_score.type != 0):\n",
    "            print(\"Skipped: %s\", midi_score)\n",
    "            continue\n",
    "        print(midi_score)\n",
    "        monoTrackMidis.append(midi_score)\n",
    "    print(monoTrackMidis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data for Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = []\n",
    "channels = []\n",
    "values1 = []\n",
    "values2 = []\n",
    "durations = []\n",
    "\n",
    "#tempos = []\n",
    "#time_signatures = []\n",
    "\n",
    "for midi in monoTrackMidis:\n",
    "    \n",
    "    print('\\n' + str(midi))\n",
    "    #print(midi.ticks_per_beat)\n",
    "    \n",
    "    commands.append('START')\n",
    "    channels.append(-1)\n",
    "    values1.append(-1)\n",
    "    values2.append(-1)\n",
    "    durations.append(0)\n",
    "    \n",
    "    #commands.append('FILE')\n",
    "    #channels.append(-1)\n",
    "    #values1.append(midi.filename)\n",
    "    #values2.append(midi.ticks_per_beat)\n",
    "    #durations.append(0)\n",
    "    \n",
    "    # All midis in the List only have one Track so we just need to look at that one\n",
    "    for i, msg in enumerate(midi.tracks[0]):\n",
    "        if type(msg) == MetaMessage:\n",
    "            if msg.type == 'set_tempo':\n",
    "                commands.append(msg.type)\n",
    "                channels.append(-1)\n",
    "                values1.append(msg.tempo)\n",
    "                values2.append(-1)\n",
    "                durations.append(msg.time)\n",
    "                continue\n",
    "            elif msg.type == 'time_signature':\n",
    "                commands.append(msg.type)\n",
    "                channels.append(-1)\n",
    "                values1.append(str(msg.numerator)+'/'+str(msg.denominator))\n",
    "                values2.append(str(msg.clocks_per_click)+'/'+ str(msg.notated_32nd_notes_per_beat))\n",
    "                durations.append(msg.time)\n",
    "                continue\n",
    "            elif msg.type == 'key_signature':\n",
    "                #commands.append(msg.type)\n",
    "                #channels.append(-1)\n",
    "                #values1.append(msg.key)\n",
    "                #values2.append(-1)\n",
    "                #durations.append(msg.time)\n",
    "                # Adds the time to the next message to not get timing wrong\n",
    "                #nextMessage = midi.tracks[0][i+1]\n",
    "                #nextMessage.time += msg.time\n",
    "                #print(nextMessage)\n",
    "                continue\n",
    "            elif msg.type == 'end_of_track':\n",
    "                commands.append(msg.type)\n",
    "                channels.append(-1)\n",
    "                values1.append(-1)\n",
    "                values2.append(-1)\n",
    "                durations.append(msg.time)\n",
    "                continue\n",
    "            elif msg.type == 'lyrics' or msg.type == 'track_name' or msg.type == 'copyright' or msg.type == 'instrument_name' or msg.type == 'marker' or msg.type == 'text' or msg.type == 'smpte_offset' or msg.type == 'channel_prefix':\n",
    "                # Adds the time to the next message to not get timing wrong\n",
    "                #nextMessage = midi.tracks[0][i+1]\n",
    "                #nextMessage.time += msg.time\n",
    "                #print(nextMessage)\n",
    "                continue\n",
    "            else:\n",
    "                print(msg)\n",
    "        elif type(msg) == Message:\n",
    "            if msg.type == 'sysex':\n",
    "                #commands.append(msg.type)\n",
    "                #channels.append(-1)\n",
    "                #values1.append(str(msg.data))\n",
    "                #values2.append(-1)\n",
    "                #durations.append(msg.time)\n",
    "                #nextMessage = midi.tracks[0][i+1]\n",
    "                #nextMessage.time += msg.time\n",
    "                #print(nextMessage)\n",
    "                continue\n",
    "                \n",
    "            commands.append(msg.type)\n",
    "            channels.append(msg.channel)\n",
    "            durations.append(msg.time)\n",
    "            \n",
    "            if msg.type == 'note_on' or msg.type == 'note_off':\n",
    "                values1.append(msg.note)\n",
    "                values2.append(msg.velocity)\n",
    "            elif msg.type == 'control_change':\n",
    "                values1.append(msg.control)\n",
    "                values2.append(msg.value)\n",
    "            elif msg.type == 'program_change':\n",
    "                values1.append(msg.program)\n",
    "                values2.append(-1)\n",
    "            elif msg.type == 'pitchwheel':\n",
    "                values1.append(msg.pitch)\n",
    "                values2.append(-1)\n",
    "            else:\n",
    "                print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct sets of all input data\n",
    "command_names, n_commands = get_distinct(commands)\n",
    "channel_names, n_channel = get_distinct(channels)\n",
    "value1_names, n_value1 = get_distinct(list(map(str, values1)))\n",
    "value2_names, n_value2 = get_distinct(list(map(str, values2)))\n",
    "duration_names, n_durations = get_distinct(durations)\n",
    "\n",
    "distincts = [command_names, n_commands, channel_names, n_channel, value1_names, n_value1, value2_names, n_value2, duration_names, n_durations]\n",
    "\n",
    "with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n",
    "    pickle.dump(distincts, f)\n",
    "\n",
    "# make the lookup dictionaries for notes and dictionaries and save\n",
    "command_to_int, int_to_command = create_lookups(command_names)\n",
    "channel_to_int, int_to_channel = create_lookups(channel_names)\n",
    "value1_to_int, int_to_value1 = create_lookups(value1_names)\n",
    "value2_to_int, int_to_value2 = create_lookups(value2_names)\n",
    "duration_to_int, int_to_duration = create_lookups(duration_names)\n",
    "\n",
    "lookups = [command_to_int, int_to_command, channel_to_int, int_to_channel, value1_to_int, int_to_value1, value2_to_int, int_to_value2, duration_to_int, int_to_duration]\n",
    "\n",
    "with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n",
    "    pickle.dump(lookups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nvalue2_to_int')\n",
    "command_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nduration_to_int')\n",
    "duration_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sequences used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values1_strings = list(map(str, values1))\n",
    "values2_strings = list(map(str, values2))\n",
    "network_input, network_output = prepare_sequences(commands, channels, values1_strings, values2_strings, durations, lookups, distincts, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#####  INPUT  ####')\n",
    "print('command input')\n",
    "print(network_input[0][0])\n",
    "print('channel input')\n",
    "print(network_input[1][0])\n",
    "print('values1 input')\n",
    "print(network_input[2][0])\n",
    "print('values2 input')\n",
    "print(network_input[3][0])\n",
    "print('durations input')\n",
    "print(network_input[4][0])\n",
    "\n",
    "print('\\n#####  OUTPUT  ####')\n",
    "print('command output')\n",
    "print(network_output[0][0])\n",
    "print('channel output')\n",
    "print(network_output[0][1])\n",
    "print('values1 output')\n",
    "print(network_output[0][2])\n",
    "print('values2 output')\n",
    "print(network_output[0][3])\n",
    "print('durations output')\n",
    "print(network_output[0][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, att_model = create_network(n_commands, n_channel, n_value1, n_value2, n_durations, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, \"weights\")\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger_custom.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights_custom.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    #, early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights_custom.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=2000000, batch_size=128\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(weights_folder, \"weights_finished.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

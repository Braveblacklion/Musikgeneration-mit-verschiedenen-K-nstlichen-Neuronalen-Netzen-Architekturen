{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pypianoroll\n",
    "import numpy as np\n",
    "from pypianoroll import Multitrack, Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "run_id = '3020'\n",
    "\n",
    "RUN_FOLDER = 'run/'\n",
    "RUN_FOLDER += run_id\n",
    "\n",
    "# Number of timestept the slices Pianorolls should have (Needs to be dividable by 16)\n",
    "pianrollLength = 128\n",
    "\n",
    "store_folder = os.path.join(RUN_FOLDER, 'store')\n",
    "weights_folder = os.path.join(RUN_FOLDER, 'weights')\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'store'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'output'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "# Number of different Notes between highest and lowest Note\n",
    "minNumDifferentNoted = 5\n",
    "# Set Note bounds for faster training\n",
    "lowestNotePossible = 20\n",
    "highestNotePossible = 108\n",
    "# possibleNotes mus be dividable by 4 else the Architekture needs to be changed\n",
    "possibleNotes = highestNotePossible - lowestNotePossible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 128, 88, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an already shaped array\n",
    "reshaped = np.load('data/preprocessed/midi_normalized_p128_dn88.npy')\n",
    "reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "@tf.function\n",
    "def custom_activation(x):\n",
    "    return (K.sigmoid(x) * K.sigmoid(x))\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "# Quelle: https://stackoverflow.com/a/43915483/9179624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(64, kernel_size = (5,5), padding = 'same', input_shape=(pianrollLength,possibleNotes,1)))\n",
    "#discriminator.add(BatchNormalization())\n",
    "discriminator.add(LeakyReLU(alpha=0.3))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(64, kernel_size = (5,5), padding = 'same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(128, activation='sigmoid'))\n",
    "discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 88, 64)       1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 88, 64)       102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 720896)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 720896)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               92274816  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 92,379,073\n",
      "Trainable params: 92,379,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "generator_initial_dense_layer_size = (int(pianrollLength/4),int(possibleNotes/4),64)\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(np.prod(generator_initial_dense_layer_size), input_shape=(z_dim,)))\n",
    "generator.add(Reshape(generator_initial_dense_layer_size))\n",
    "#generator.add(Dropout(0.2))\n",
    "#generator.add(BatchNormalization())\n",
    "\n",
    "generator.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='bilinear'))\n",
    "generator.add(Conv2D(16, kernel_size = (5,5), padding='same'))\n",
    "#generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.3))\n",
    "#generator.add(Dropout(0.2))\n",
    "\n",
    "generator.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='bilinear'))\n",
    "generator.add(Conv2D(32, kernel_size = (5,5), padding='same'))\n",
    "#generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.3))\n",
    "#generator.add(Dropout(0.2))\n",
    " \n",
    "generator.add(Conv2DTranspose(64, kernel_size = (5,5), padding = 'same'))\n",
    "#generator.add(Conv2D(8, kernel_size = (5,5), padding='same'))\n",
    "#generator.add(BatchNormalization())\n",
    "generator.add(LeakyReLU(alpha=0.3))\n",
    "#generator.add(Dropout(0.2))\n",
    "\n",
    "generator.add(Conv2D(filters = 1, kernel_size = (5,5), activation=custom_activation, padding = 'same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 45056)             4550656   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 44, 16)        25616     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 44, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 88, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 88, 32)       12832     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128, 88, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 128, 88, 64)       51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 88, 1)        1601      \n",
      "=================================================================\n",
      "Total params: 4,641,969\n",
      "Trainable params: 4,641,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_d = RMSprop(lr=0.0001, clipvalue=1.0, decay=6e-8)\n",
    "\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(optimizer=optimizer_d, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "optimizer_g = RMSprop(lr=0.0001, clipvalue=1.0, decay=3e-8)\n",
    "# FÃ¼rs GAN soll nur der Generator trainiert werden\n",
    "discriminator.trainable = False\n",
    "\n",
    "GANModel = Sequential()\n",
    "GANModel.add(generator)\n",
    "GANModel.add(discriminator)\n",
    "GANModel.compile(optimizer=optimizer_g, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 128, 88, 1)        4641969   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 92379073  \n",
      "=================================================================\n",
      "Total params: 97,021,042\n",
      "Trainable params: 4,641,969\n",
      "Non-trainable params: 92,379,073\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GANModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANModel.save(os.path.join(weights_folder, 'GANModel_init.h5'))\n",
    "discriminator.save(os.path.join(weights_folder, 'discriminator_init.h5'))\n",
    "generator.save(os.path.join(weights_folder, 'generator_init.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GANModel.load_weights(os.path.join(weights_folder, 'GANModel.h5'))\n",
    "#discriminator.load_weights(os.path.join(weights_folder, 'discriminator.h5'))\n",
    "#generator.load_weights(os.path.join(weights_folder, 'generator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_custom(epochs, batch_size=128):\n",
    "    # Save the Generator and discriminator models\n",
    "    #save_model(generator, os.path.join(RUN_FOLDER, 'images/generator'))\n",
    "    #save_model(discriminator, os.path.join(RUN_FOLDER, 'images/discriminator'))\n",
    "    #save_model(GANModel, os.path.join(RUN_FOLDER, r\"images/GANModel\"))\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    print(valid.shape)\n",
    "    \n",
    "    # Some variables for validations\n",
    "    d_loss_real_list = []\n",
    "    d_acc_real_list = []\n",
    "    d_loss_fake_list = []\n",
    "    d_acc_fake_list = []\n",
    "    best_loss = 0.5\n",
    "    g_loss = [100, 0]\n",
    "    d_loss_real, d_acc_real = 99, 0 \n",
    "    d_loss_fake, d_acc_fake = 99, 0\n",
    "    d_loss = 99\n",
    "    d_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------      \n",
    "        current_discriminator_accuracy = 0\n",
    "        # Trains the Discriminator until it reached an accuracy of over 80% on the fake images\n",
    "        # If the max. accuracy is higher the generator needs to learn more to reach its min. accuracy\n",
    "        while current_discriminator_accuracy < 1:\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, reshaped.shape[0], batch_size)\n",
    "            imgs = reshaped[idx]\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real, d_acc_real =  discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake, d_acc_fake =  discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "            d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "            current_discriminator_accuracy = d_acc\n",
    "            print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)]\" % (epoch, d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake))\n",
    "\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        current_generator_accuracy = 0\n",
    "        # Trains the generator, until it reaches an accuracy of 100%\n",
    "        while current_generator_accuracy < 1:\n",
    "            noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = GANModel.train_on_batch(noise, valid)\n",
    "            \n",
    "            current_generator_accuracy = g_loss[1]\n",
    "            print (\"%d [G loss: %.3f] [G acc: %.3f]\" % (epoch, g_loss[0], g_loss[1]))\n",
    "            \n",
    "        GANModel.save(os.path.join(weights_folder, 'GANModel_'+str(epoch)+'_loss_'+str(g_loss[0])+'.h5'))\n",
    "        discriminator.save(os.path.join(weights_folder, 'discriminator_'+str(epoch)+'_loss_'+str(d_loss)+'.h5'))\n",
    "        generator.save(os.path.join(weights_folder, 'generator_'+str(epoch)+'_loss_'+str(g_loss[0])+'.h5'))\n",
    "        \n",
    "        # Save an example\n",
    "        fig=plt.figure(figsize=(64, 64))\n",
    "        plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(RUN_FOLDER, \"output/\"+str(epoch)+\".png\"), format='png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Discriminator too strong for Generator to be able to learn\n",
    "        #if (d_loss < 0.05):\n",
    "            #print('Discirminator too strong')\n",
    "            #break\n",
    "        # Plot the progress\n",
    "        #if (epoch%10 == 0):\n",
    "        print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake, g_loss[0], g_loss[1]))\n",
    "        #else:\n",
    "        #    print (\"%d [G loss: %.3f] [G acc: %.3f]\" % (epoch, g_loss[0], g_loss[1]))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        #if epoch % save_interval == 0:\n",
    "            ##self.save_imgs(epoch)\n",
    "        \n",
    "# Quelle(https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training test --> Train generator until 100% then train discriminator until 50% Repeat\n",
    "train_custom(1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "# plt.xlim(0, 2000)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "plt.savefig(os.path.join(RUN_FOLDER, \"output/loss_chart.png\"), format='png')\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "generated_images = generator.predict(noise)\n",
    "#print(discriminator.predict(generated_images))\n",
    "print(GANModel.predict(noise))\n",
    "#print(GANModel.predict(noise))\n",
    "for i in range(generated_images.shape[0]):\n",
    "    fig=plt.figure(figsize=(64, 64))\n",
    "    plt.subplot(1, 8, i+1)\n",
    "    plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedPlot = reshaped[58].reshape(128,88)\n",
    "for i in range(1):\n",
    "    fig=plt.figure(figsize=(64, 64))\n",
    "    plt.subplot(1, 8, i+1)\n",
    "    plt.imshow(reshapedPlot, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANModel_loaded = GANModel\n",
    "discriminator_loaded = discriminator\n",
    "generator_loaded = generator\n",
    "GANModel_loaded.load_weights(os.path.join(weights_folder, 'weights-GANModel.h5'))\n",
    "discriminator_loaded.load_weights(os.path.join(weights_folder, 'weights-discriminator.h5'))\n",
    "generator_loaded.load_weights(os.path.join(weights_folder, 'weights-generator.h5'))\n",
    "\n",
    "batch_size=10\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "generated_images = generator_loaded.predict(noise)\n",
    "#print(discriminator.predict(generated_images))\n",
    "print(GANModel_loaded.predict(noise))\n",
    "#print(GANModel.predict(noise))\n",
    "for i in range(generated_images.shape[0]):\n",
    "    fig=plt.figure(figsize=(64, 64))\n",
    "    plt.subplot(1, 8, i+1)\n",
    "    plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_img = generated_images[1].reshape(128, 88)\n",
    "result = np.zeros((pianrollLength, 128))\n",
    "result[:,lowestNotePossible:highestNotePossible] = gen_img\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test convert an image back to see the Splitted Arrays Plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Midi_File(img):\n",
    "    gen_img = img.reshape(128, 88)\n",
    "    result = np.zeros((pianrollLength, 128))\n",
    "    result[:,lowestNotePossible:highestNotePossible] = gen_img\n",
    "    result.shape\n",
    "    result = result * 255.\n",
    "    track = Track(pianoroll=result, program=0, is_drum=False,name='my awesome piano')\n",
    "    track.plot()\n",
    "    multi = Multitrack()\n",
    "    multi.tracks[0] = track\n",
    "    multi.write('output/test_0002.mid')\n",
    "    #multi.write('output/test_zebra.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_Midi_File(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(GANModel, to_file=os.path.join(RUN_FOLDER ,'images/GANModel.png'), show_shapes = True, show_layer_names = True)\n",
    "plot_model(discriminator, to_file=os.path.join(RUN_FOLDER ,'images/discriminator.png'), show_shapes = True, show_layer_names = True)\n",
    "plot_model(generator, to_file=os.path.join(RUN_FOLDER ,'images/generator.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(run_folder):\n",
    "    GANModel.save(os.path.join(RUN_FOLDER, 'images/GANModel.h5'))\n",
    "    discriminator.save(os.path.join(RUN_FOLDER, 'images/discriminator.h5'))\n",
    "    generator.save(os.path.join(RUN_FOLDER, 'images/generator.h5'))\n",
    "    #pickle.dump(open( os.path.join(run_folder, \"obj.pkl\"), \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GANModel.save(os.path.join(RUN_FOLDER, 'images/GANModel.h5'))\n",
    "discriminator.save(os.path.join(RUN_FOLDER, 'images/discriminator.h5'))\n",
    "generator.save(os.path.join(RUN_FOLDER, 'images/generator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GANModel.save(os.path.join(weights_folder, 'weights-okay-GANModel.h5'))\n",
    "#discriminator.save(os.path.join(weights_folder, 'weights-okay-discriminator.h5'))\n",
    "#generator.save(os.path.join(weights_folder, 'weights-okay-generator.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_normal(epochs, batch_size=128):\n",
    "    # Save the Generator and discriminator models\n",
    "    #save_model(generator, os.path.join(RUN_FOLDER, 'images/generator'))\n",
    "    #save_model(discriminator, os.path.join(RUN_FOLDER, 'images/discriminator'))\n",
    "    #save_model(GANModel, os.path.join(RUN_FOLDER, r\"images/GANModel\"))\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    best_loss = 0.5\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        # Select a random half of images\n",
    "        idx = np.random.randint(0, reshaped.shape[0], batch_size)\n",
    "        imgs = reshaped[idx]\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------      \n",
    "        d_loss_real, d_acc_real =  discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake, d_acc_fake =  discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss =  0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "        print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)]\" % (epoch, d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake))\n",
    "\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        g_loss = GANModel.train_on_batch(noise, valid)\n",
    "        print (\"%d [G loss: %.3f] [G acc: %.3f]\" % (epoch, g_loss[0], g_loss[1]))\n",
    "        \n",
    "        # Save an example\n",
    "        fig=plt.figure(figsize=(64, 64))\n",
    "        plt.imshow(gen_imgs[0, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(RUN_FOLDER, \"images/\"+str(epoch)+\".png\"), format='png')\n",
    "        plt.close()\n",
    "    \n",
    "        print (\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\" % (epoch, d_loss, d_loss_real, d_loss_fake, d_acc, d_acc_real, d_acc_fake, g_loss[0], g_loss[1]))\n",
    "        \n",
    "# Quelle(https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses = np.load(os.path.join(RUN_FOLDER, \"D_loss.npy\"))\n",
    "g_losses = np.load(os.path.join(RUN_FOLDER, \"G_loss.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
